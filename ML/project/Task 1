import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import matplotlib.pyplot as plt
import os
# Constants
m = 1.0  # Mass (kg)
b = 10  # Friction coefficient
k_p = 50  # Proportional gain
k_d = 10   # Derivative gain
dt = 0.01  # Time step
num_samples = 1000  # Number of samples in dataset

# Generate synthetic data for trajectory tracking
t = np.linspace(0, 10, num_samples)
q_target = np.sin(t)
dot_q_target = np.cos(t)

# Initial conditions for training data generation
q = 0
dot_q = 0
X = []
Y = []

for i in range(num_samples):
    # PD control output
    tau = k_p * (q_target[i] - q) + k_d * (dot_q_target[i] - dot_q)
    # Ideal motor dynamics (variable mass for realism)
    #m_real = m * (1 + 0.1 * np.random.randn())  # Mass varies by +/-10%
    ddot_q_real = (tau - b * dot_q) / m
    
    # Calculate error
    ddot_q_ideal = (tau) / m
    ddot_q_error = ddot_q_ideal - ddot_q_real
    
    # Store data
    X.append([q, dot_q, q_target[i], dot_q_target[i]])
    Y.append(ddot_q_error)
    
    # Update state
    dot_q += ddot_q_real * dt
    q += dot_q * dt

# Convert data for PyTorch
X_tensor = torch.tensor(X, dtype=torch.float32)
Y_tensor = torch.tensor(Y, dtype=torch.float32).view(-1, 1)




# MLP Model Definition
class ShallowCoreectorMLP(nn.Module):
    def __init__(self):
        super(ShallowCoreectorMLP, self).__init__()
        self.layers = nn.Sequential(
            nn.Linear(4, hidden_nodes),
            nn.ReLU(),
            nn.Linear(hidden_nodes, hidden_nodes),
            nn.ReLU(),
            nn.Linear(hidden_nodes, 1)
        )

    def forward(self, x):
        return self.layers(x)


class DeepCorrectorMLP(nn.Module):
    def __init__(self):
        super(DeepCorrectorMLP, self).__init__()
        self.layers = nn.Sequential(
            nn.Linear(4, hidden_nodes),
            nn.ReLU(),
            nn.Linear(hidden_nodes, hidden_nodes),
            nn.ReLU(),
            nn.Linear(hidden_nodes, hidden_nodes),
            nn.ReLU(),
            nn.Linear(hidden_nodes, 1)
        )

    def forward(self, x):
        return self.layers(x)




# Define training parameters
epochs=1000


#Task 1.1
# Test for different number of hidden nodes
learning_rate = 0.00001
batch_size =32
for hidden_nodes in [32, 64, 96, 128]:

# Task 1.3
# Test for different learning rates
# batch_size = 32
# hidden_nodes = 32
# for learning_rate in [0.0001,0.001, 0.01, 0.1, 1]:

# Task 1.4
# # Test for different batch sizes
# hidden_nodes =32
# learning_rate = 0.00001
# for batch_size in [64, 128, 256, 1000]:

# Dataset and DataLoader
    dataset = TensorDataset(X_tensor, Y_tensor)
    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    # Initialize model, loss function, and optimizer
    # Change model to DeepCorrectorMLP for Task 1.2
    model= ShallowCoreectorMLP()
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    train_losses = []

    # Training Loop
    for epoch in range(epochs):
        epoch_loss = 0
        for data, target in train_loader:
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()

        train_losses.append(epoch_loss / len(train_loader))
        print(f'Epoch {epoch+1}/{epochs}, Loss: {train_losses[-1]:.6f}')


    # Testing Phase: Simulate trajectory tracking
    q_test = 0
    dot_q_test = 0
    q_real = []
    q_real_corrected = []


    # integration with only PD Control
    for i in range(len(t)):
        tau = k_p * (q_target[i] - q_test) + k_d * (dot_q_target[i] - dot_q_test)
        ddot_q_real = (tau - b * dot_q_test) / m
        dot_q_test += ddot_q_real * dt
        q_test += dot_q_test * dt
        q_real.append(q_test)

    q_test = 0
    dot_q_test = 0
    for i in range(len(t)):
        # Apply MLP correction
        tau = k_p * (q_target[i] - q_test) + k_d * (dot_q_target[i] - dot_q_test)
        inputs = torch.tensor([q_test, dot_q_test, q_target[i], dot_q_target[i]], dtype=torch.float32)
        correction = model(inputs.unsqueeze(0)).item()
        ddot_q_corrected =(tau - b * dot_q_test + correction) / m
        dot_q_test += ddot_q_corrected * dt
        q_test += dot_q_test * dt
        q_real_corrected.append(q_test)


    save_dir = r"C:/Users/Roger/Pictures/Final2/Task1"
    os.makedirs(save_dir, exist_ok=True)


    # Plot results
    plt.figure(figsize=(12, 6))
    plt.plot(t, q_target, 'r-', label='Target')
    plt.plot(t, q_real, 'b--', label='PD Only')
    plt.plot(t, q_real_corrected, 'g:', label='PD + MLP Correction ' + ', hidden nodes' + str(hidden_nodes) + ', learning rate  ' + str(learning_rate) + ' , batch size ' + str(batch_size))
    plt.title('Trajectory Tracking with and without MLP Correction'+ str(hidden_nodes) + ', hidden nodes' + str(hidden_nodes) + ', learning rate  ' + str(learning_rate) + ' , batch size ' + str(batch_size))
    plt.xlabel('Time [s]')
    plt.ylabel('Position')
    plt.legend()
    trajectory_plot_path = os.path.join(save_dir, f'trajectory_tracking_{hidden_nodes}_hidden_nodes_lr_{learning_rate}_batch_{batch_size}.png')
    plt.savefig(trajectory_plot_path)
    plt.show()

    plt.figure(figsize=(12, 6))
    plt.plot(train_losses, label = '' + str(hidden_nodes) + ', hidden nodes' + str(hidden_nodes) + ', learning rate  ' + str(learning_rate) + ' , batch size ' + str(batch_size))
    plt.title('Training Loss'+ str(hidden_nodes) + ', hidden nodes' + str(hidden_nodes) + ', learning rate  ' + str(learning_rate) + ' , batch size ' + str(batch_size))
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    loss_plot_path = os.path.join(save_dir, f'training_loss_{hidden_nodes}_hidden_nodes_lr_{learning_rate}_batch_{batch_size}.png')
    plt.savefig(loss_plot_path)
    plt.show()

    
    # plt.figure(figsize=(12, 6))
    # plt.plot(Y_tensor.cpu().np(), label = 'Output in training ' + str(hidden_nodes) + ' hidden nodes')
    # plt.plot(model(X_tensor).cpu().np(),label = 'Coreection that MLP produces'+ str(hidden_nodes) + ' hidden nodes')
    # plt.title('Accuracy of ShallowCorrectorMLP'+ str(hidden_nodes) + ' hidden nodes')
    # plt.xlabel('Time')
    # plt.ylabel('Output')
    # plt.legend()
    # plt.show()



# # Testing Phase: Simulate trajectory tracking
# q_test = 0
# dot_q_test = 0
# q_real = []
# q_real_corrected = []


# # integration with only PD Control
# for i in range(len(t)):
#     tau = k_p * (q_target[i] - q_test) + k_d * (dot_q_target[i] - dot_q_test)
#     ddot_q_real = (tau - b * dot_q_test) / m
#     dot_q_test += ddot_q_real * dt
#     q_test += dot_q_test * dt
#     q_real.append(q_test)

# q_test = 0
# dot_q_test = 0
# for i in range(len(t)):
#     # Apply MLP correction
#     tau = k_p * (q_target[i] - q_test) + k_d * (dot_q_target[i] - dot_q_test)
#     inputs = torch.tensor([q_test, dot_q_test, q_target[i], dot_q_target[i]], dtype=torch.float32)
#     correction = model(inputs.unsqueeze(0)).item()
#     ddot_q_corrected =(tau - b * dot_q_test + correction) / m
#     dot_q_test += ddot_q_corrected * dt
#     q_test += dot_q_test * dt
#     q_real_corrected.append(q_test)

# # Plot results
# plt.figure(figsize=(12, 6))
# plt.plot(t, q_target, 'r-', label='Target')
# plt.plot(t, q_real, 'b--', label='PD Only')
# plt.plot(t, q_real_corrected, 'g:', label='PD + MLP Correction')
# plt.title('Trajectory Tracking with and without MLP Correction')
# plt.xlabel('Time [s]')
# plt.ylabel('Position')
# plt.legend()
# plt.show()
